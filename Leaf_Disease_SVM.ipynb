{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c3e33f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hll\n"
     ]
    }
   ],
   "source": [
    "# Packages that may need to be installed to run\n",
    "#pip install opencv-python\n",
    "print(\"hll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "00149a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt       \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dcf4a90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tomato Bacterial Spot Images: 1000\n",
      "Total Cleaned Images: 1000\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "# Data source cite: https://github.com/gabrieldgf4/PlantVillage-Dataset\n",
    "# Repost from the plantvillage.org repository that is no longer available\n",
    "\n",
    "# Setting filters for the images hsv colors\n",
    "low_hsv = (0,60,0)\n",
    "high_hsv = (179,255,255)\n",
    "\n",
    "\n",
    "#cleaning the images\n",
    "def cleaning_image(images):\n",
    "    clean_image = []\n",
    "    for image in images:\n",
    "        gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(gray_scale, low_hsv,high_hsv)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel=np.ones((8,8),dtype=np.uint8))\n",
    "        clean_image.append(cv2.bitwise_and(image, image,mask=mask))\n",
    "    return clean_image\n",
    "\n",
    "# Getting healthy leaf images (#1000)\n",
    "Toma_healthy = [cv2.imread(file) for file in glob.glob(r'TomatoDataset/Tomato_healthy/*.JPG')]\n",
    "Toma_healthy_cleaned = cleaning_image(Toma_healthy)\n",
    "\n",
    "# Getting moldy leaf images (# 952)\n",
    "Toma_mold  = [cv2.imread(file) for file in glob.glob(r'TomatoDataset/Tomato_leaf_mold/*.JPG')]\n",
    "Toma_mold_cleaned = cleaning_image(Toma_mold)\n",
    "\n",
    "# Getting bacterial spot images (# 1000)\n",
    "Toma_bact_spot  = [cv2.imread(file) for file in glob.glob(r'TomatoDataset/Tomato_bacterial_spot/*.JPG')]\n",
    "\n",
    "Toma_bact_spot_clean = cleaning_image(Toma_bact_spot)\n",
    "\n",
    "print(f\"Total Tomato Bacterial Spot Images: {len(Toma_bact_spot)}\")\n",
    "print(f\"Total Cleaned Images: {len(Toma_bact_spot_clean)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b450ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Checker\n",
    "# cv2.imshow(\"Image\", Toma_bact_spot_clean[88])\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "861e97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature gathering code\n",
    "# Takes in image list and label, returns pandas datafram of features\n",
    "\n",
    "def feature_gathering(images, label):\n",
    "    red_mean = []\n",
    "    blue_mean = []\n",
    "    green_mean = []\n",
    "    contrast = [] # not used yet. Need to download a package to get this feature\n",
    "    labels = [label]*len(images)\n",
    "    for image in images:\n",
    "        red_mean.append(np.mean(image[:,:,0]))\n",
    "        blue_mean.append(np.mean(image[:,:,1]))\n",
    "        green_mean.append(np.mean(image[:,:,2]))\n",
    "        \n",
    "    return pd.DataFrame({\"label\":labels, \"RedMean\":red_mean, \"BlueMean\":blue_mean, \"GreenMean\": green_mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8e372b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncleaned images\n",
    "Toma_healthy_df = feature_gathering(Toma_healthy, 1)\n",
    "Toma_mold_df = feature_gathering(Toma_mold, 2)\n",
    "Toma_bact_spot_df = feature_gathering(Toma_bact_spot, 3)\n",
    "\n",
    "uncleaned_leaves_df = pd.concat([Toma_healthy_df,Toma_mold_df,Toma_bact_spot_df], axis =0)\n",
    "unclean_X = uncleaned_leaves_df.drop(columns= [\"label\"], axis = 1)\n",
    "unclean_y = uncleaned_leaves_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6969a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned images\n",
    "Toma_healthy_df = feature_gathering(Toma_healthy_cleaned, 1)\n",
    "Toma_mold_df  = feature_gathering(Toma_mold_cleaned, 2)\n",
    "Toma_bact_spot_df = feature_gathering(Toma_bact_spot, 3)\n",
    "\n",
    "cleaned_leaves_df = pd.concat([Toma_healthy_df,Toma_mold_df,Toma_bact_spot_df], axis =0)\n",
    "clean_X = cleaned_leaves_df.drop(columns= [\"label\"], axis = 1)\n",
    "clean_y = cleaned_leaves_df[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b33ef3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_label(name_str):\n",
    "    # Remove spaces and parentheses, then take the first two parts split by '_'\n",
    "    name_str = name_str.replace(\" \", \"\")\n",
    "    name_str = name_str.translate(name_str.maketrans(\"\", \"\", \"()\"))\n",
    "    parts = name_str.split(\"_\")\n",
    "    return ''.join(parts[:2])\n",
    "\n",
    "def normalize_desc(folder, sub_folder):\n",
    "    text = folder + \" - \" + sub_folder \n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.replace(\".\", \"\")\n",
    "    return text.strip()\n",
    "\n",
    "def print_progress(val, val_len, folder, sub_folder, filename, bar_size=10):\n",
    "    progr = \"#\" * round(val * bar_size / val_len) + \" \" * round((val_len - val) * bar_size / val_len)\n",
    "    print(f\"[{progr}] folder: {folder}/{sub_folder}/ ----> file: {filename}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "438e2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_gathering_with_glcm(images, label):\n",
    "    # Define GLCM parameters\n",
    "    properties = ['dissimilarity', 'correlation', 'homogeneity', 'contrast', 'ASM', 'energy']\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    angle_names = ['0', '45', '90', '135']\n",
    "    \n",
    "    data = []\n",
    "    for image in images:\n",
    "        if image is None:\n",
    "            # If an image failed to load, assign NaN to all features\n",
    "            row = {\"RedMean\": np.nan, \"GreenMean\": np.nan, \"BlueMean\": np.nan}\n",
    "            for prop in properties:\n",
    "                for ang in angle_names:\n",
    "                    row[f\"{prop}_{ang}\"] = np.nan\n",
    "            row[\"label\"] = label\n",
    "            data.append(row)\n",
    "            continue\n",
    "        \n",
    "        # Extract color features (note: OpenCV uses BGR)\n",
    "        red_mean = np.mean(image[:, :, 2])\n",
    "        green_mean = np.mean(image[:, :, 1])\n",
    "        blue_mean = np.mean(image[:, :, 0])\n",
    "        \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        glcm = graycomatrix(gray, distances=[5], angles=angles, levels=256, symmetric=True, normed=True)\n",
    "        \n",
    "        # Extract texture features from the GLCM for each property and angle\n",
    "        glcm_features = {}\n",
    "        for prop in properties:\n",
    "            vals = graycoprops(glcm, prop).flatten()  \n",
    "            for i, ang in enumerate(angle_names):\n",
    "                glcm_features[f\"{prop}_{ang}\"] = vals[i]\n",
    "        \n",
    "        # Combine features into single row\n",
    "        row = {\n",
    "            \"RedMean\": red_mean,\n",
    "            \"GreenMean\": green_mean,\n",
    "            \"BlueMean\": blue_mean\n",
    "        }\n",
    "        row.update(glcm_features)\n",
    "        row[\"label\"] = label\n",
    "        data.append(row)\n",
    "        \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b79da253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lbp_histogram(image, num_points=8, radius=1, method=\"uniform\"):\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # Compute LBP codes\n",
    "    lbp = local_binary_pattern(gray, num_points, radius, method=method)\n",
    "    \n",
    "    # Build the histogram\n",
    "    n_bins = num_points + 2\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "    \n",
    "    # Normalize\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b6ca4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_gathering_with_lbp(images, label):\n",
    "    data = []\n",
    "    \n",
    "    for image in images:\n",
    "        # If image is None, skip or fill with NaNs\n",
    "        if image is None:\n",
    "            row = {\n",
    "                \"RedMean\": np.nan,\n",
    "                \"GreenMean\": np.nan,\n",
    "                \"BlueMean\": np.nan\n",
    "            }\n",
    "            for i in range(10):\n",
    "                row[f\"LBP_{i}\"] = np.nan\n",
    "            row[\"label\"] = label\n",
    "            data.append(row)\n",
    "            continue\n",
    "        \n",
    "        # Color means (OpenCV = BGR)\n",
    "        red_mean   = np.mean(image[:, :, 2])\n",
    "        green_mean = np.mean(image[:, :, 1])\n",
    "        blue_mean  = np.mean(image[:, :, 0])\n",
    "        \n",
    "        # Compute LBP histogram\n",
    "        lbp_hist = compute_lbp_histogram(image, num_points=8, radius=1, method=\"uniform\")\n",
    "        \n",
    "        # Build row\n",
    "        row = {\n",
    "            \"RedMean\": red_mean,\n",
    "            \"GreenMean\": green_mean,\n",
    "            \"BlueMean\": blue_mean\n",
    "        }\n",
    "        \n",
    "        # Add LBP histogram bins as separate features\n",
    "        for i, val in enumerate(lbp_hist):\n",
    "            row[f\"LBP_{i}\"] = val\n",
    "        \n",
    "        row[\"label\"] = label\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3b9e75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for uncleaned images\n",
    "Toma_healthy_df_unclean = feature_gathering_with_glcm(Toma_healthy, 1)\n",
    "Toma_mold_df_unclean    = feature_gathering_with_glcm(Toma_mold, 2)\n",
    "Toma_bact_spot_df_unclean = feature_gathering_with_glcm(Toma_bact_spot, 3)\n",
    "\n",
    "uncleaned_leaves_df = pd.concat([Toma_healthy_df_unclean, Toma_mold_df_unclean, Toma_bact_spot_df_unclean], axis=0, ignore_index=True)\n",
    "unclean_X_glcm = uncleaned_leaves_df.drop(columns=[\"label\"], axis=1)\n",
    "unclean_y_glcm = uncleaned_leaves_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "40eea0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for cleaned images\n",
    "Toma_healthy_df_clean = feature_gathering_with_glcm(Toma_healthy_cleaned, 1)\n",
    "Toma_mold_df_clean    = feature_gathering_with_glcm(Toma_mold_cleaned, 2)\n",
    "Toma_bact_spot_df_clean = feature_gathering_with_glcm(Toma_bact_spot_clean, 3)\n",
    "\n",
    "cleaned_leaves_df = pd.concat([Toma_healthy_df_clean, Toma_mold_df_clean, Toma_bact_spot_df_clean], axis=0, ignore_index=True)\n",
    "clean_X_glcm = cleaned_leaves_df.drop(columns=[\"label\"], axis=1)\n",
    "clean_y_glcm = cleaned_leaves_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e0e126b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Toma_healthy_df_unclean_lbp = feature_gathering_with_lbp(Toma_healthy, 1)\n",
    "Toma_mold_df_unclean_lbp    = feature_gathering_with_lbp(Toma_mold, 2)\n",
    "Toma_bact_spot_df_unclean_lbp = feature_gathering_with_lbp(Toma_bact_spot, 3)\n",
    "\n",
    "uncleaned_leaves_df = pd.concat([\n",
    "    Toma_healthy_df_unclean_lbp,\n",
    "    Toma_mold_df_unclean_lbp,\n",
    "    Toma_bact_spot_df_unclean_lbp\n",
    "], axis=0, ignore_index=True)\n",
    "\n",
    "unclean_X_lbph = uncleaned_leaves_df.drop(columns=[\"label\"], axis=1)\n",
    "unclean_y_lbph = uncleaned_leaves_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8999debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Toma_healthy_df_clean_lbp = feature_gathering_with_lbp(Toma_healthy_cleaned, 1)\n",
    "Toma_mold_df_clean_lbp    = feature_gathering_with_lbp(Toma_mold_cleaned, 2)\n",
    "Toma_bact_spot_df_clean_lbp = feature_gathering_with_lbp(Toma_bact_spot_clean, 3)\n",
    "\n",
    "cleaned_leaves_df = pd.concat([\n",
    "    Toma_healthy_df_clean_lbp,\n",
    "    Toma_mold_df_clean_lbp,\n",
    "    Toma_bact_spot_df_clean_lbp\n",
    "], axis=0, ignore_index=True)\n",
    "\n",
    "clean_X_lbph = cleaned_leaves_df.drop(columns=[\"label\"], axis=1)\n",
    "clean_y_lbph = cleaned_leaves_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "932feec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Model Maker\n",
    "Leaf_svm = SVC(kernel='rbf', C = 100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5fa690b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unclean Cross Val score =  0.8086154374713697\n",
      "The unclean Cross Val score with GLCM =  0.9458039395327532\n",
      "The unclean Cross Val score with LBPH =  0.7523797526339899\n"
     ]
    }
   ],
   "source": [
    "# Cross_val_score unclean\n",
    "kf = KFold(n_splits= 10, shuffle = True)\n",
    "scores = cross_val_score(Leaf_svm, unclean_X, unclean_y, cv=kf)\n",
    "print(\"The unclean Cross Val score = \",np.average(np.absolute(scores)))\n",
    "\n",
    "kf = KFold(n_splits= 10, shuffle = True)\n",
    "scores = cross_val_score(Leaf_svm, unclean_X_glcm, unclean_y_glcm, cv=kf)\n",
    "print(\"The unclean Cross Val score with GLCM = \",np.average(np.absolute(scores)))\n",
    "\n",
    "kf = KFold(n_splits= 10, shuffle = True)\n",
    "scores = cross_val_score(Leaf_svm, unclean_X_lbph, unclean_y_lbph, cv=kf)\n",
    "print(\"The unclean Cross Val score with LBPH = \",np.average(np.absolute(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e4cf2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The clean Cross Val score =  0.949527027027027\n",
      "The clean Cross Val score with GLCM =  0.8485833715071003\n",
      "The clean Cross Val score with LBPH =  0.8065735226752178\n"
     ]
    }
   ],
   "source": [
    "# Cross_val_score clean\n",
    "kf = KFold(n_splits= 10, shuffle = True)\n",
    "scores = cross_val_score(Leaf_svm, clean_X, clean_y, cv=kf)\n",
    "print(\"The clean Cross Val score = \",np.average(np.absolute(scores)))\n",
    "\n",
    "kf = KFold(n_splits= 10, shuffle = True)\n",
    "scores = cross_val_score(Leaf_svm, clean_X_glcm, clean_y_glcm, cv=kf)\n",
    "print(\"The clean Cross Val score with GLCM = \",np.average(np.absolute(scores)))\n",
    "\n",
    "kf = KFold(n_splits= 10, shuffle = True)\n",
    "scores = cross_val_score(Leaf_svm, clean_X_lbph, clean_y_lbph, cv=kf)\n",
    "print(\"The clean Cross Val score with LBPH = \",np.average(np.absolute(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53009175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
